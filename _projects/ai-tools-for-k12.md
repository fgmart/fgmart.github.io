---
layout: page
title: AI for K-12
description: 
img: /assets/img/developing-ai-tools-utsa.png
importance: 1
category: active
related_publications: vahedian2024introducing, martin2024chemaistry, 10.1145/3545945.3569772, 10.1145/3576123.3576127, Touretzky_Gardner-McCune_Martin_Seehorn_2019, 10.1145/3544549.3573808
---

As part of the [AI-CARING NSF Institute](https://ai-caring.org), we
are developing a set of interactive tools to introduce novice
learners to ideas in AI.

### AI Chef Trainer

![]({{
 "/assets/img/aitools/aicheftrainer-hero.png"}}){:style="height:150px"}


AI Chef Trainer was developed by was developed by UTSA Ph.D. candidate
Saniya Vahedian Movahed. Its goal is to introduce students to key
ideas via the engaging task of recipe recommendation. Students select
ingredients to see what recipes are predicted by the AI Chef; then
they enter their own recipes (retraining the AI) and then test to see how their recipes can then be recommended by the AI Chef.

Slides for using AI Chef Trainer with your students are available [here](https://utsacloud-my.sharepoint.com/:p:/g/personal/fred_martin_utsa_edu/EZPP08Cxzz1KpMaNq18LstABcJ5sK3imLjSToSvjMfNfHA?e=5Tq9h4).

Try it out here! [AI Chef Trainer](https://aichef.pythonanywhere.com/)

### DoodleIt


![]({{
 "/assets/img/publication_preview/doodleit.png"}}){:style="height:150px"}

Taking inspiration from Google's [Quick,
Draw!](https://quickdraw.withgoogle.com/) demo, Vaishali Mahipal (MS
in CS, 2022) led the development of
DoodleIt, a browser-based tool that
demonstrates how Convolutional Neural Networks (CNNs) perform image
recognition.

DoodleIt was presented as a [poster at SIGCSE
'23](https://docs.google.com/presentation/d/14X3tlSGPwgSf_RMmYygnPqCjGEXMvyPY/present)
and a [paper at ACE '23](/assets/pdf/3576123.3576127.pdf).  Here are
[worksheets for the hands-on kernel filter
activities](https://drive.google.com/drive/folders/1B0SiX3ol50j0p_C1AdLlewe_aHqUSyNK)
we created as part of developing the tool.

You can interact with DoodleIt at this [live web
link](https://tinyurl.com/mydoodleit).

### ChemAIstry

![]({{
 "/assets/img/aitools/chemaistry.jpg"}}){:style="height:150px"}

ChemAIstry is an interactive software tool for children which
demonstrates training and classification in machine learning. Students
select which everyday items are safe to bring into a chemistry lab
(e.g., a lab coat is safe; pizza is not). These selections serve as
training input for a decision tree classifier. After training,
students see how the trained model performs in classifying new
objects.

The software was developed by Garima Jain (BS in CS 2023) and Vaishali
Mahipal (MS in CS 2022) with assistance from Dr. Ismaila Sanusi and
Srija Ghosh (now a computer science student at Cornell University).

ChemAIstry was presented at [SIGCSE
'24](https://sigcse2024.sigcse.org/details/sigcse-ts-2024-Papers-1/181/ChemAIstry-A-Novel-Software-Tool-for-Teaching-Model-Training-in-K-8-Education). Here
is [the paper](/assets/pdf/3626252.3630804.pdf).  Interact with the
[live version!](https://engaging-computing.github.io/ChemAIstry/)

### Ask Me Anything

![]({{
 "/assets/img/aitools/ask-me-anything.png"}}){:style="height:150px"}

Ask Me Anything (AMA) is a specialized chatbot that answers only
topic-specific questions in three areas&#151;astronomy, sneakers and shoes,
and dinosaurs.

AMA was developed by UTSA Ph.D. candidate Saniya Vahedian Movahed
(with UMass Lowell undergraduate Erika Salas) and is being used to
study children's attitudes of trust and confidence in AI chatbots.

AMA was presented at SIGCSE '24 in a poster entitled [Perception,
Trust, Attitudes, and Models: Introducing Children to AI and Machine Learning with Five Software Exhibits](https://sigcse2024.sigcse.org/track/sigcse-ts-2024-posters#program).


### AI for American Sign Language

![]({{
 "/assets/img/aitools/ai-for-asl.png"}}){:style="height:150px"}

AI for American Sign Language (AI for ASL) teaches children hand
gestures for several letters of the American Sign Language (ASL)
alphabet while introducing them to image recognition and models.

It was developed by James Dimino and Andrew Farrell during a Spring
2023 class at UMass Lowell and adapted for the web by Angela Wang (now
an undergrad in CS at Cornell University) and Ryan Maradiaga
(finishing his BS in CS at UMass Lowell).

Here is a live web link to [AI for
ASL](https://engaging-computing.github.io/AI-for-ASL/SignInterpreter/src/). 

### FaunaForest

![]({{
 "/assets/img/aitools/fauna-forest.png"}}){:style="height:150px"}

FaunaForest was created by Pragathi Durga Rajarajan and Adrian
Cisneros as part of the [Spring 2024 Developing AI Tools for
K-12](../../teaching/DevelopingAITools/) course at UTSA.

FaunaForest aims to teach K-12 students about decision trees via three
levels of interactive decision tree puzzles. Each puzzle involves
completing a decision tree that has blank mystery nodes in such a way
that it will correctly classify various animals.

Try it [here](https://engaging-computing.github.io/FaunaForest/)!

